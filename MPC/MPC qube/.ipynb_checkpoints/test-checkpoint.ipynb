{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import gym\n",
    "import torch.utils.data as data\n",
    "from dynamics import *\n",
    "from controller import *\n",
    "from utils import *\n",
    "from quanser_robots.common import GentlyTerminating\n",
    "\n",
    "# datasets:  numpy array, size:[sample number, input dimension]\n",
    "# labels:  numpy array, size:[sample number, output dimension]\n",
    "\n",
    "env_id =\"Qube-v0\" # \"CartPole-v0\"\n",
    "env = GentlyTerminating(gym.make(env_id))\n",
    "config_path = \"config.yml\"\n",
    "config = load_config(config_path)\n",
    "#print_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinye/projects/rl/RL-project/MPC/MPC qube/dynamics.py:208: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if datasets == None:\n",
      "/home/xinye/projects/rl/RL-project/MPC/MPC qube/dynamics.py:212: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if labels == None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect random dataset shape:  (4329, 7)\n"
     ]
    }
   ],
   "source": [
    "model = DynamicModel(config)\n",
    "\n",
    "data_fac = DatasetFactory(env,config)\n",
    "data_fac.collect_random_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training step per epoch [55]\n",
      "Epoch [50/500], Training Loss: 0.06064808, Test Loss: 0.06149180\n",
      "Epoch [100/500], Training Loss: 0.05886089, Test Loss: 0.05924280\n",
      "Epoch [150/500], Training Loss: 0.05818230, Test Loss: 0.06072282\n",
      "Epoch [200/500], Training Loss: 0.05725430, Test Loss: 0.05917601\n",
      "Epoch [250/500], Training Loss: 0.05566457, Test Loss: 0.05872102\n",
      "Epoch [300/500], Training Loss: 0.05542131, Test Loss: 0.05889234\n",
      "Epoch [350/500], Training Loss: 0.05565484, Test Loss: 0.06071570\n",
      "Epoch [400/500], Training Loss: 0.05715850, Test Loss: 0.06050992\n",
      "Epoch [450/500], Training Loss: 0.05410156, Test Loss: 0.06346160\n",
      "Epoch [500/500], Training Loss: 0.05326184, Test Loss: 0.06036323\n"
     ]
    }
   ],
   "source": [
    "loss = model.train(data_fac.random_trainset,data_fac.random_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config[\"mpc_config\"][\"horizon\"] = 15\n",
    "config[\"mpc_config\"][\"numb_bees\"] = 8\n",
    "config[\"mpc_config\"][\"max_itrs\"] = 20\n",
    "config[\"mpc_config\"][\"gamma\"] = 0.95\n",
    "mpc = MPC(env,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin the [0] reinforce process, collecting data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinye/projects/rl/RL-project/MPC/MPC qube/dynamics.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda()\n"
     ]
    }
   ],
   "source": [
    "rewards_list = []\n",
    "for itr in range(config[\"dataset_config\"][\"n_mpc_itrs\"]):\n",
    "    print(\"Begin the reinforce process [%s], collecting data ...\" % itr)\n",
    "    rewards = data_fac.collect_mpc_dataset(mpc,model)\n",
    "    trainset, testset = data_fac.make_dataset()\n",
    "    rewards_list += rewards\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title('Reward Trend with %s iteration' % itr)\n",
    "    plt.plot(rewards_list)\n",
    "    plt.savefig(\"storage/reward-\" + str(model.exp_number) + \".png\")\n",
    "    \n",
    "    loss = model.train(trainset,testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatasetFactory(object):\n",
    "    def __init__(self, env, config):\n",
    "        self.env = env\n",
    "        dataset_config = config[\"dataset_config\"]\n",
    "        self.load_flag = dataset_config[\"load_flag\"]\n",
    "        self.load_path = dataset_config[\"load_path\"]\n",
    "        self.n_max_steps = dataset_config[\"n_max_steps\"]\n",
    "        self.n_random_episodes = dataset_config[\"n_random_episodes\"]\n",
    "        self.testset_split = dataset_config[\"testset_split\"]\n",
    "        self.n_mpc_episodes = dataset_config[\"n_mpc_episodes\"]\n",
    "        self.mpc_dataset_split = dataset_config[\"mpc_dataset_split\"]\n",
    "        self.n_mpc_itrs = dataset_config[\"n_mpc_itrs\"]\n",
    "        self.save_flag = dataset_config[\"save_flag\"]\n",
    "        self.save_path = dataset_config[\"save_path\"]\n",
    "        self.random_dataset = None\n",
    "        self.random_trainset = None\n",
    "        self.random_testset = None\n",
    "        self.mpc_dataset = None\n",
    "        self.mpc_dataset_len = 0\n",
    "        self.trainset = None\n",
    "        if self.load_flag:\n",
    "            self.all_dataset = self.load_dataset()\n",
    "        else:\n",
    "            self.all_dataset = None\n",
    "\n",
    "    # numpy array, collect n_random_episodes data with maximum n_max_steps steps per episode\n",
    "    def collect_random_dataset(self):\n",
    "        datasets = None\n",
    "        labels = None\n",
    "        for i in range(self.n_random_episodes):\n",
    "            data_tmp = []\n",
    "            label_tmp = []\n",
    "            state_old = self.env.reset()\n",
    "            for j in range(self.n_max_steps):\n",
    "                action = self.env.action_space.sample()\n",
    "                data_tmp.append(np.concatenate((state_old, action)))\n",
    "                state_new, reward, done, info = self.env.step(action)\n",
    "                label_tmp.append(state_new - state_old)\n",
    "                if done:\n",
    "                    break\n",
    "                state_old = state_new\n",
    "            data_tmp = np.array(data_tmp)\n",
    "            label_tmp = np.array(label_tmp)\n",
    "            if datasets == None:\n",
    "                datasets = data_tmp\n",
    "            else:\n",
    "                datasets = np.concatenate((datasets, data_tmp))\n",
    "            if labels == None:\n",
    "                labels = label_tmp\n",
    "            else:\n",
    "                labels = np.concatenate((labels, label_tmp))\n",
    "        data_and_label = np.concatenate((datasets, labels), axis=1)\n",
    "        # Merge the data and label into one array and then shuffle\n",
    "        np.random.shuffle(data_and_label)\n",
    "        print(\"Collect random dataset shape: \", datasets.shape)\n",
    "        testset_len = int(datasets.shape[0] * self.testset_split)\n",
    "        data_len = datasets.shape[1]\n",
    "        self.random_testset = {\"data\": data_and_label[:testset_len, :data_len],\n",
    "                               \"label\": data_and_label[:testset_len, data_len:]}\n",
    "        self.random_trainset = {\"data\": data_and_label[testset_len:, :data_len],\n",
    "                                \"label\": data_and_label[testset_len:, data_len:]}\n",
    "        self.random_dataset = {\"data\": datasets, \"label\": labels}\n",
    "        self.all_dataset = self.random_dataset\n",
    "\n",
    "    def collect_mpc_dataset(self, mpc, dynamic_model):\n",
    "        datasets = None\n",
    "        labels = None\n",
    "        reward_episodes = []\n",
    "        for i in range(self.n_mpc_episodes):\n",
    "            data_tmp = []\n",
    "            label_tmp = []\n",
    "            reward_episode = 0\n",
    "            state_old = self.env.reset()\n",
    "            for j in range(self.n_max_steps):\n",
    "                action = mpc.act(state_old, dynamic_model)\n",
    "                action = np.array([action])\n",
    "                data_tmp.append(np.concatenate((state_old, action)))\n",
    "                state_new, reward, done, info = self.env.step(action)\n",
    "                reward_episode += reward\n",
    "                label_tmp.append(state_new - state_old)\n",
    "                if done:\n",
    "                    break\n",
    "                state_old = state_new\n",
    "            data_tmp = np.array(data_tmp)\n",
    "            label_tmp = np.array(label_tmp)\n",
    "            if datasets == None:\n",
    "                datasets = data_tmp\n",
    "            else:\n",
    "                datasets = np.concatenate((datasets, data_tmp))\n",
    "            if labels == None:\n",
    "                labels = label_tmp\n",
    "            else:\n",
    "                labels = np.concatenate((labels, label_tmp))\n",
    "            reward_episodes.append(reward_episode)\n",
    "            print(f\"Episode [{i}/{self.n_mpc_episodes}], Reward: {reward_episode:.8f}\")\n",
    "        self.mpc_dataset = {\"data\": datasets, \"label\": labels}\n",
    "        self.mpc_dataset_len = datasets.shape[0]\n",
    "        print(\"Totally collect %s data based on MPC\" % self.mpc_dataset_len)\n",
    "        all_datasets = np.concatenate((datasets, self.all_dataset[\"data\"]))\n",
    "        all_labels = np.concatenate((labels, self.all_dataset[\"label\"]))\n",
    "        self.all_dataset = {\"data\": all_datasets, \"label\": all_labels}\n",
    "        if self.save_flag:\n",
    "            self.save_datasets(self.all_dataset)\n",
    "        return reward_episodes\n",
    "\n",
    "    def make_dataset(self):\n",
    "        # calculate how many samples needed from the all datasets\n",
    "        all_length = int(self.mpc_dataset_len / self.mpc_dataset_split)\n",
    "        sample_length = all_length - self.mpc_dataset_len\n",
    "        sample_length = min(self.all_dataset.shape[0], sample_length)\n",
    "        print(\"Sample %s training data from all previous dataset, total training sample: %s\" % (\n",
    "        sample_length, all_length))\n",
    "        data_and_label = np.concatenate((self.all_dataset[\"data\"], self.all_dataset[\"label\"]), axis=1)\n",
    "        # Merge the data and label into one array and then shuffle\n",
    "        np.random.shuffle(data_and_label)\n",
    "        testset_len = min(int(all_length * self.testset_split), self.all_dataset.shape[0])\n",
    "        data_len = self.mpc_dataset.shape[1]\n",
    "\n",
    "        trainset_data = np.concatenate((self.mpc_dataset[\"data\"], data_and_label[:sample_length, :data_len]))\n",
    "        trainset_label = np.concatenate((self.mpc_dataset[\"label\"], data_and_label[:sample_length, data_len:]))\n",
    "        testset_data = data_and_label[testset_len:, :data_len]\n",
    "        testset_label = data_and_label[testset_len:, data_len:]\n",
    "        trainset = {\"data\": trainset_data, \"label\": trainset_label}\n",
    "        testset = {\"data\": testset_data, \"label\": testset_label}\n",
    "        return trainset, testset\n",
    "\n",
    "    # Save dictionary dataset\n",
    "    def save_datasets(self,data):\n",
    "        print(\"Saving all datas to %s\" % self.save_path)\n",
    "        with open(self.save_path, 'wb') as f:  # open file with write-mode\n",
    "            pickle.dump(data, f, -1)  # serialize and save object\n",
    "\n",
    "    def load_dataset(self):\n",
    "        print(\"Load datas from %s\" % self.load_path)\n",
    "        with open(self.load_path, 'rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
