{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "*** model configuration ***\n",
      "load_model: false\n",
      "model_path: storage/exp_1.ckpt\n",
      "n_actions: 1\n",
      "n_hidden: 1\n",
      "n_states: 6\n",
      "size_hidden: 512\n",
      "use_cuda: true\n",
      "\n",
      "*** train configuration ***\n",
      "batch_size: 256\n",
      "exp_number: 1\n",
      "learning_rate: 0.001\n",
      "n_epochs: 60\n",
      "save_loss_fig: true\n",
      "save_loss_fig_frequency: 10\n",
      "save_model_flag: true\n",
      "save_model_path: storage/exp_1.ckpt\n",
      "\n",
      "************************\n",
      "*** dataset configuration ***\n",
      "load_flag: false\n",
      "load_path: storage/data_exp_1.pkl\n",
      "min_train_samples: 6000\n",
      "mpc_dataset_split: 0.5\n",
      "n_max_steps: 20000\n",
      "n_mpc_episodes: 4\n",
      "n_mpc_itrs: 100\n",
      "n_random_episodes: 800\n",
      "save_flag: true\n",
      "save_path: storage/data_exp_1.pkl\n",
      "testset_split: 0.2\n",
      "\n",
      "************************\n",
      "*** MPC controller configuration ***\n",
      "action_high: 12\n",
      "action_low: -12\n",
      "gamma: 0.99\n",
      "horizon: 12\n",
      "max_itrs: 15\n",
      "numb_bees: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import gym\n",
    "import torch.utils.data as data\n",
    "from dynamics import *\n",
    "from controller import *\n",
    "from utils import *\n",
    "from quanser_robots.common import GentlyTerminating\n",
    "import time\n",
    "\n",
    "# datasets:  numpy array, size:[sample number, input dimension]\n",
    "# labels:  numpy array, size:[sample number, output dimension]\n",
    "\n",
    "env_id = \"DoublePendulum-v0\"\n",
    "env = GentlyTerminating(gym.make(env_id))\n",
    "config_path = \"config-1.yml\"\n",
    "config = load_config(config_path)\n",
    "print_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect random dataset shape:  (61253, 7)\n"
     ]
    }
   ],
   "source": [
    "model = DynamicModel(config)\n",
    "data_fac = DatasetFactory(env,config)\n",
    "data_fac.collect_random_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training step per epoch [192]\n",
      "Epoch [10/60], Training Loss: 0.00009838, Test Loss: 0.00008559\n",
      "Epoch [20/60], Training Loss: 0.00004314, Test Loss: 0.00003684\n",
      "Epoch [30/60], Training Loss: 0.00003676, Test Loss: 0.00003913\n",
      "Epoch [40/60], Training Loss: 0.00002508, Test Loss: 0.00005212\n",
      "Epoch [50/60], Training Loss: 0.00002567, Test Loss: 0.00002503\n",
      "Epoch [60/60], Training Loss: 0.00002130, Test Loss: 0.00002211\n"
     ]
    }
   ],
   "source": [
    "loss = model.train(data_fac.random_trainset,data_fac.random_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinye/projects/rl/RL-project/MPC/MPC-Double/dynamics.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAGDCAYAAAALTociAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nArWIiIiIyBT8/8vR1H5UDdISAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_model_validation(env,n_sample=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpc = MPC(env,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************\n",
      "The reinforce process [0], collecting data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinye/projects/rl/RL-project/MPC/MPC-Double/dynamics.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [0/4], Reward: 23.21185266, Step: [213/20000]\n",
      "Episode [1/4], Reward: 27.52539609, Step: [251/20000]\n",
      "Episode [2/4], Reward: 32.57582927, Step: [292/20000]\n",
      "Episode [3/4], Reward: 25.56254045, Step: [230/20000]\n",
      "Totally collect 990 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5010 training data from all previous dataset, total training sample: 6000\n",
      "Consume 749.9628100395203 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00002731, Test Loss: 0.00003835\n",
      "Epoch [20/60], Training Loss: 0.00003321, Test Loss: 0.00005501\n",
      "Epoch [30/60], Training Loss: 0.00001721, Test Loss: 0.00004732\n",
      "Epoch [40/60], Training Loss: 0.00003010, Test Loss: 0.00003484\n",
      "Epoch [50/60], Training Loss: 0.00001537, Test Loss: 0.00001344\n",
      "Epoch [60/60], Training Loss: 0.00004381, Test Loss: 0.00006862\n",
      "**********************************************\n",
      "The reinforce process [1], collecting data ...\n",
      "Episode [0/4], Reward: 25.19212036, Step: [233/20000]\n",
      "Episode [1/4], Reward: 17.41741909, Step: [168/20000]\n",
      "Episode [2/4], Reward: 31.41385615, Step: [283/20000]\n",
      "Episode [3/4], Reward: 19.12097915, Step: [183/20000]\n",
      "Totally collect 871 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5129 training data from all previous dataset, total training sample: 6000\n",
      "Consume 681.2446403503418 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001685, Test Loss: 0.00002177\n",
      "Epoch [20/60], Training Loss: 0.00003438, Test Loss: 0.00001586\n",
      "Epoch [30/60], Training Loss: 0.00002167, Test Loss: 0.00002050\n",
      "Epoch [40/60], Training Loss: 0.00003079, Test Loss: 0.00002946\n",
      "Epoch [50/60], Training Loss: 0.00001075, Test Loss: 0.00000863\n",
      "Epoch [60/60], Training Loss: 0.00002020, Test Loss: 0.00001808\n",
      "**********************************************\n",
      "The reinforce process [2], collecting data ...\n",
      "Episode [0/4], Reward: 34.25226052, Step: [303/20000]\n",
      "Episode [1/4], Reward: 24.11185000, Step: [221/20000]\n",
      "Episode [2/4], Reward: 19.52884307, Step: [185/20000]\n",
      "Episode [3/4], Reward: 26.24960446, Step: [242/20000]\n",
      "Totally collect 955 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5045 training data from all previous dataset, total training sample: 6000\n",
      "Consume 850.8109786510468 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001801, Test Loss: 0.00000927\n",
      "Epoch [20/60], Training Loss: 0.00001436, Test Loss: 0.00001227\n",
      "Epoch [30/60], Training Loss: 0.00001779, Test Loss: 0.00001245\n",
      "Epoch [40/60], Training Loss: 0.00001341, Test Loss: 0.00001384\n",
      "Epoch [50/60], Training Loss: 0.00001852, Test Loss: 0.00001539\n",
      "Epoch [60/60], Training Loss: 0.00001858, Test Loss: 0.00002626\n",
      "**********************************************\n",
      "The reinforce process [3], collecting data ...\n",
      "Episode [0/4], Reward: 20.28678937, Step: [195/20000]\n",
      "Episode [1/4], Reward: 23.87714967, Step: [224/20000]\n",
      "Episode [2/4], Reward: 18.69763494, Step: [180/20000]\n",
      "Episode [3/4], Reward: 20.37372318, Step: [196/20000]\n",
      "Totally collect 799 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5201 training data from all previous dataset, total training sample: 6000\n",
      "Consume 767.6524736881256 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001524, Test Loss: 0.00003329\n",
      "Epoch [20/60], Training Loss: 0.00001155, Test Loss: 0.00001248\n",
      "Epoch [30/60], Training Loss: 0.00001927, Test Loss: 0.00001954\n",
      "Epoch [40/60], Training Loss: 0.00003181, Test Loss: 0.00003730\n",
      "Epoch [50/60], Training Loss: 0.00004083, Test Loss: 0.00003689\n",
      "Epoch [60/60], Training Loss: 0.00003037, Test Loss: 0.00002682\n",
      "**********************************************\n",
      "The reinforce process [4], collecting data ...\n",
      "Episode [0/4], Reward: 25.04326441, Step: [231/20000]\n",
      "Episode [1/4], Reward: 47.01266503, Step: [406/20000]\n",
      "Episode [2/4], Reward: 22.74043918, Step: [212/20000]\n",
      "Episode [3/4], Reward: 31.91005674, Step: [285/20000]\n",
      "Totally collect 1138 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4862 training data from all previous dataset, total training sample: 6000\n",
      "Consume 860.4937417507172 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00002227, Test Loss: 0.00003192\n",
      "Epoch [20/60], Training Loss: 0.00002128, Test Loss: 0.00004938\n",
      "Epoch [30/60], Training Loss: 0.00001822, Test Loss: 0.00001965\n",
      "Epoch [40/60], Training Loss: 0.00001464, Test Loss: 0.00000917\n",
      "Epoch [50/60], Training Loss: 0.00001197, Test Loss: 0.00000888\n",
      "Epoch [60/60], Training Loss: 0.00001129, Test Loss: 0.00000971\n",
      "**********************************************\n",
      "The reinforce process [5], collecting data ...\n",
      "Episode [0/4], Reward: 22.42942165, Step: [212/20000]\n",
      "Episode [1/4], Reward: 22.01819711, Step: [205/20000]\n",
      "Episode [2/4], Reward: 18.44154239, Step: [180/20000]\n",
      "Episode [3/4], Reward: 30.50027447, Step: [276/20000]\n",
      "Totally collect 877 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5123 training data from all previous dataset, total training sample: 6000\n",
      "Consume 878.8188591003418 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001380, Test Loss: 0.00001520\n",
      "Epoch [20/60], Training Loss: 0.00001703, Test Loss: 0.00001059\n",
      "Epoch [30/60], Training Loss: 0.00001492, Test Loss: 0.00000941\n",
      "Epoch [40/60], Training Loss: 0.00003144, Test Loss: 0.00001320\n",
      "Epoch [50/60], Training Loss: 0.00003152, Test Loss: 0.00007458\n",
      "Epoch [60/60], Training Loss: 0.00002150, Test Loss: 0.00005387\n",
      "**********************************************\n",
      "The reinforce process [6], collecting data ...\n",
      "Episode [0/4], Reward: 45.93077590, Step: [397/20000]\n",
      "Episode [1/4], Reward: 27.74043337, Step: [251/20000]\n",
      "Episode [2/4], Reward: 21.58706610, Step: [201/20000]\n",
      "Episode [3/4], Reward: 17.95701537, Step: [176/20000]\n",
      "Totally collect 1029 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4971 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1155.378166437149 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000953, Test Loss: 0.00001913\n",
      "Epoch [20/60], Training Loss: 0.00001266, Test Loss: 0.00004243\n",
      "Epoch [30/60], Training Loss: 0.00001166, Test Loss: 0.00000896\n",
      "Epoch [40/60], Training Loss: 0.00002351, Test Loss: 0.00001926\n",
      "Epoch [50/60], Training Loss: 0.00001210, Test Loss: 0.00001105\n",
      "Epoch [60/60], Training Loss: 0.00003928, Test Loss: 0.00002396\n",
      "**********************************************\n",
      "The reinforce process [7], collecting data ...\n",
      "Episode [0/4], Reward: 21.05997363, Step: [199/20000]\n",
      "Episode [1/4], Reward: 47.75084884, Step: [415/20000]\n",
      "Episode [2/4], Reward: 29.53777776, Step: [268/20000]\n",
      "Episode [3/4], Reward: 41.18313001, Step: [356/20000]\n",
      "Totally collect 1242 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4758 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1372.5745384693146 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001864, Test Loss: 0.00002063\n",
      "Epoch [20/60], Training Loss: 0.00001659, Test Loss: 0.00001502\n",
      "Epoch [30/60], Training Loss: 0.00001677, Test Loss: 0.00002563\n",
      "Epoch [40/60], Training Loss: 0.00001641, Test Loss: 0.00001287\n",
      "Epoch [50/60], Training Loss: 0.00002632, Test Loss: 0.00002271\n",
      "Epoch [60/60], Training Loss: 0.00000940, Test Loss: 0.00001259\n",
      "**********************************************\n",
      "The reinforce process [8], collecting data ...\n",
      "Episode [0/4], Reward: 16.40447733, Step: [163/20000]\n",
      "Episode [1/4], Reward: 25.33337571, Step: [233/20000]\n",
      "Episode [2/4], Reward: 14.50389450, Step: [146/20000]\n",
      "Episode [3/4], Reward: 19.16086922, Step: [186/20000]\n",
      "Totally collect 732 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5268 training data from all previous dataset, total training sample: 6000\n",
      "Consume 813.0103003978729 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00002565, Test Loss: 0.00000885\n",
      "Epoch [20/60], Training Loss: 0.00003662, Test Loss: 0.00003406\n",
      "Epoch [30/60], Training Loss: 0.00001482, Test Loss: 0.00002725\n",
      "Epoch [40/60], Training Loss: 0.00001878, Test Loss: 0.00001638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/60], Training Loss: 0.00001462, Test Loss: 0.00001820\n",
      "Epoch [60/60], Training Loss: 0.00001536, Test Loss: 0.00001339\n",
      "**********************************************\n",
      "The reinforce process [9], collecting data ...\n",
      "Episode [0/4], Reward: 18.70223147, Step: [177/20000]\n",
      "Episode [1/4], Reward: 20.13592742, Step: [191/20000]\n",
      "Episode [2/4], Reward: 28.27624743, Step: [258/20000]\n",
      "Episode [3/4], Reward: 19.15864280, Step: [183/20000]\n",
      "Totally collect 813 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5187 training data from all previous dataset, total training sample: 6000\n",
      "Consume 909.2783329486847 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001425, Test Loss: 0.00002081\n",
      "Epoch [20/60], Training Loss: 0.00001059, Test Loss: 0.00001118\n",
      "Epoch [30/60], Training Loss: 0.00000945, Test Loss: 0.00001485\n",
      "Epoch [40/60], Training Loss: 0.00001670, Test Loss: 0.00002680\n",
      "Epoch [50/60], Training Loss: 0.00001980, Test Loss: 0.00001088\n",
      "Epoch [60/60], Training Loss: 0.00001813, Test Loss: 0.00002667\n",
      "**********************************************\n",
      "The reinforce process [10], collecting data ...\n",
      "Episode [0/4], Reward: 34.51911079, Step: [307/20000]\n",
      "Episode [1/4], Reward: 32.82743524, Step: [294/20000]\n",
      "Episode [2/4], Reward: 18.50324924, Step: [180/20000]\n",
      "Episode [3/4], Reward: 30.39535557, Step: [275/20000]\n",
      "Totally collect 1060 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4940 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1282.837839603424 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001276, Test Loss: 0.00001134\n",
      "Epoch [20/60], Training Loss: 0.00001072, Test Loss: 0.00002278\n",
      "Epoch [30/60], Training Loss: 0.00001161, Test Loss: 0.00000825\n",
      "Epoch [40/60], Training Loss: 0.00001129, Test Loss: 0.00004589\n",
      "Epoch [50/60], Training Loss: 0.00001572, Test Loss: 0.00001123\n",
      "Epoch [60/60], Training Loss: 0.00000832, Test Loss: 0.00001907\n",
      "**********************************************\n",
      "The reinforce process [11], collecting data ...\n",
      "Episode [0/4], Reward: 21.98707051, Step: [206/20000]\n",
      "Episode [1/4], Reward: 16.04894809, Step: [162/20000]\n",
      "Episode [2/4], Reward: 18.21870005, Step: [176/20000]\n",
      "Episode [3/4], Reward: 18.04480171, Step: [177/20000]\n",
      "Totally collect 725 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5275 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1063.4030468463898 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001250, Test Loss: 0.00001412\n",
      "Epoch [20/60], Training Loss: 0.00002282, Test Loss: 0.00001072\n",
      "Epoch [30/60], Training Loss: 0.00003892, Test Loss: 0.00003217\n",
      "Epoch [40/60], Training Loss: 0.00001211, Test Loss: 0.00000927\n",
      "Epoch [50/60], Training Loss: 0.00000854, Test Loss: 0.00000546\n",
      "Epoch [60/60], Training Loss: 0.00000702, Test Loss: 0.00000671\n",
      "**********************************************\n",
      "The reinforce process [12], collecting data ...\n",
      "Episode [0/4], Reward: 19.59664832, Step: [186/20000]\n",
      "Episode [1/4], Reward: 34.34065365, Step: [303/20000]\n",
      "Episode [2/4], Reward: 30.58182675, Step: [274/20000]\n",
      "Episode [3/4], Reward: 36.40174466, Step: [321/20000]\n",
      "Totally collect 1088 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4912 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1391.0612897872925 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001675, Test Loss: 0.00000783\n",
      "Epoch [20/60], Training Loss: 0.00002929, Test Loss: 0.00003465\n",
      "Epoch [30/60], Training Loss: 0.00001246, Test Loss: 0.00002017\n",
      "Epoch [40/60], Training Loss: 0.00002883, Test Loss: 0.00002176\n",
      "Epoch [50/60], Training Loss: 0.00000896, Test Loss: 0.00001291\n",
      "Epoch [60/60], Training Loss: 0.00002051, Test Loss: 0.00002383\n",
      "**********************************************\n",
      "The reinforce process [13], collecting data ...\n",
      "Episode [0/4], Reward: 30.96288113, Step: [279/20000]\n",
      "Episode [1/4], Reward: 15.38660381, Step: [153/20000]\n",
      "Episode [2/4], Reward: 17.32818450, Step: [168/20000]\n",
      "Episode [3/4], Reward: 50.23733312, Step: [431/20000]\n",
      "Totally collect 1035 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4965 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1307.3429057598114 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000484, Test Loss: 0.00000668\n",
      "Epoch [20/60], Training Loss: 0.00001036, Test Loss: 0.00000890\n",
      "Epoch [30/60], Training Loss: 0.00001437, Test Loss: 0.00001694\n",
      "Epoch [40/60], Training Loss: 0.00002281, Test Loss: 0.00003181\n",
      "Epoch [50/60], Training Loss: 0.00001877, Test Loss: 0.00001480\n",
      "Epoch [60/60], Training Loss: 0.00000859, Test Loss: 0.00002569\n",
      "**********************************************\n",
      "The reinforce process [14], collecting data ...\n",
      "Episode [0/4], Reward: 24.96590265, Step: [229/20000]\n",
      "Episode [1/4], Reward: 22.48160191, Step: [212/20000]\n",
      "Episode [2/4], Reward: 43.19908120, Step: [374/20000]\n",
      "Episode [3/4], Reward: 20.66535452, Step: [194/20000]\n",
      "Totally collect 1013 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4987 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1313.1119792461395 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00002274, Test Loss: 0.00001687\n",
      "Epoch [20/60], Training Loss: 0.00000783, Test Loss: 0.00001599\n",
      "Epoch [30/60], Training Loss: 0.00001059, Test Loss: 0.00000812\n",
      "Epoch [40/60], Training Loss: 0.00001042, Test Loss: 0.00000955\n",
      "Epoch [50/60], Training Loss: 0.00001540, Test Loss: 0.00000713\n",
      "Epoch [60/60], Training Loss: 0.00001576, Test Loss: 0.00001543\n",
      "**********************************************\n",
      "The reinforce process [15], collecting data ...\n",
      "Episode [0/4], Reward: 17.17230101, Step: [168/20000]\n",
      "Episode [1/4], Reward: 26.74676388, Step: [246/20000]\n",
      "Episode [2/4], Reward: 14.80862418, Step: [149/20000]\n",
      "Episode [3/4], Reward: 28.66514050, Step: [260/20000]\n",
      "Totally collect 827 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5173 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1079.5789487361908 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001362, Test Loss: 0.00000709\n",
      "Epoch [20/60], Training Loss: 0.00001662, Test Loss: 0.00001582\n",
      "Epoch [30/60], Training Loss: 0.00003170, Test Loss: 0.00002298\n",
      "Epoch [40/60], Training Loss: 0.00001066, Test Loss: 0.00003016\n",
      "Epoch [50/60], Training Loss: 0.00001045, Test Loss: 0.00007493\n",
      "Epoch [60/60], Training Loss: 0.00001278, Test Loss: 0.00001274\n",
      "**********************************************\n",
      "The reinforce process [16], collecting data ...\n",
      "Episode [0/4], Reward: 20.99557885, Step: [200/20000]\n",
      "Episode [1/4], Reward: 23.40028878, Step: [219/20000]\n",
      "Episode [2/4], Reward: 19.24671241, Step: [183/20000]\n",
      "Episode [3/4], Reward: 20.24975117, Step: [190/20000]\n",
      "Totally collect 796 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5204 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1093.7944567203522 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001476, Test Loss: 0.00003449\n",
      "Epoch [20/60], Training Loss: 0.00000990, Test Loss: 0.00000697\n",
      "Epoch [30/60], Training Loss: 0.00002271, Test Loss: 0.00001355\n",
      "Epoch [40/60], Training Loss: 0.00001508, Test Loss: 0.00002201\n",
      "Epoch [50/60], Training Loss: 0.00001451, Test Loss: 0.00001745\n",
      "Epoch [60/60], Training Loss: 0.00001482, Test Loss: 0.00001697\n",
      "**********************************************\n",
      "The reinforce process [17], collecting data ...\n",
      "Episode [0/4], Reward: 46.46089139, Step: [402/20000]\n",
      "Episode [1/4], Reward: 26.91565021, Step: [244/20000]\n",
      "Episode [2/4], Reward: 17.79543627, Step: [170/20000]\n",
      "Episode [3/4], Reward: 22.87880121, Step: [214/20000]\n",
      "Totally collect 1034 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4966 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1328.0833718776703 s in this iteration\n",
      "Total training step per epoch [24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/60], Training Loss: 0.00002145, Test Loss: 0.00002099\n",
      "Epoch [20/60], Training Loss: 0.00002350, Test Loss: 0.00001060\n",
      "Epoch [30/60], Training Loss: 0.00001434, Test Loss: 0.00001332\n",
      "Epoch [40/60], Training Loss: 0.00002180, Test Loss: 0.00002055\n",
      "Epoch [50/60], Training Loss: 0.00000979, Test Loss: 0.00001162\n",
      "Epoch [60/60], Training Loss: 0.00001794, Test Loss: 0.00001904\n",
      "**********************************************\n",
      "The reinforce process [18], collecting data ...\n",
      "Episode [0/4], Reward: 29.61823306, Step: [266/20000]\n",
      "Episode [1/4], Reward: 44.47498913, Step: [385/20000]\n",
      "Episode [2/4], Reward: 15.72492627, Step: [157/20000]\n",
      "Episode [3/4], Reward: 22.94221223, Step: [214/20000]\n",
      "Totally collect 1026 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4974 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1392.4750204086304 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000912, Test Loss: 0.00001522\n",
      "Epoch [20/60], Training Loss: 0.00001144, Test Loss: 0.00001003\n",
      "Epoch [30/60], Training Loss: 0.00000940, Test Loss: 0.00000777\n",
      "Epoch [40/60], Training Loss: 0.00000782, Test Loss: 0.00001316\n",
      "Epoch [50/60], Training Loss: 0.00002539, Test Loss: 0.00002365\n",
      "Epoch [60/60], Training Loss: 0.00001423, Test Loss: 0.00002387\n",
      "**********************************************\n",
      "The reinforce process [19], collecting data ...\n",
      "Episode [0/4], Reward: 27.06626736, Step: [245/20000]\n",
      "Episode [1/4], Reward: 19.25651857, Step: [184/20000]\n",
      "Episode [2/4], Reward: 15.22072525, Step: [151/20000]\n",
      "Episode [3/4], Reward: 16.70188476, Step: [166/20000]\n",
      "Totally collect 750 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5250 training data from all previous dataset, total training sample: 6000\n",
      "Consume 990.1540505886078 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000772, Test Loss: 0.00000743\n",
      "Epoch [20/60], Training Loss: 0.00002000, Test Loss: 0.00010835\n",
      "Epoch [30/60], Training Loss: 0.00001187, Test Loss: 0.00000921\n",
      "Epoch [40/60], Training Loss: 0.00001779, Test Loss: 0.00002166\n",
      "Epoch [50/60], Training Loss: 0.00000744, Test Loss: 0.00001069\n",
      "Epoch [60/60], Training Loss: 0.00000929, Test Loss: 0.00000980\n",
      "**********************************************\n",
      "The reinforce process [20], collecting data ...\n",
      "Episode [0/4], Reward: 42.16055174, Step: [367/20000]\n",
      "Episode [1/4], Reward: 30.33238595, Step: [272/20000]\n",
      "Episode [2/4], Reward: 25.52237446, Step: [235/20000]\n",
      "Episode [3/4], Reward: 30.44959613, Step: [274/20000]\n",
      "Totally collect 1152 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4848 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1689.5628266334534 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000866, Test Loss: 0.00001649\n",
      "Epoch [20/60], Training Loss: 0.00001474, Test Loss: 0.00001886\n",
      "Epoch [30/60], Training Loss: 0.00000747, Test Loss: 0.00000985\n",
      "Epoch [40/60], Training Loss: 0.00001303, Test Loss: 0.00001340\n",
      "Epoch [50/60], Training Loss: 0.00001663, Test Loss: 0.00000794\n",
      "Epoch [60/60], Training Loss: 0.00002180, Test Loss: 0.00001557\n",
      "**********************************************\n",
      "The reinforce process [21], collecting data ...\n",
      "Episode [0/4], Reward: 41.60589216, Step: [364/20000]\n",
      "Episode [1/4], Reward: 26.63623003, Step: [243/20000]\n",
      "Episode [2/4], Reward: 47.16794807, Step: [409/20000]\n",
      "Episode [3/4], Reward: 25.53770719, Step: [235/20000]\n",
      "Totally collect 1255 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4745 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1882.761999130249 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001046, Test Loss: 0.00001161\n",
      "Epoch [20/60], Training Loss: 0.00001256, Test Loss: 0.00001431\n",
      "Epoch [30/60], Training Loss: 0.00003805, Test Loss: 0.00004471\n",
      "Epoch [40/60], Training Loss: 0.00002393, Test Loss: 0.00001958\n",
      "Epoch [50/60], Training Loss: 0.00000726, Test Loss: 0.00001502\n",
      "Epoch [60/60], Training Loss: 0.00001182, Test Loss: 0.00000586\n",
      "**********************************************\n",
      "The reinforce process [22], collecting data ...\n",
      "Episode [0/4], Reward: 14.12375635, Step: [144/20000]\n",
      "Episode [1/4], Reward: 14.63985767, Step: [147/20000]\n",
      "Episode [2/4], Reward: 32.19658930, Step: [288/20000]\n",
      "Episode [3/4], Reward: 19.86114567, Step: [189/20000]\n",
      "Totally collect 772 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5228 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1065.333760023117 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000710, Test Loss: 0.00000722\n",
      "Epoch [20/60], Training Loss: 0.00001946, Test Loss: 0.00002945\n",
      "Epoch [30/60], Training Loss: 0.00001235, Test Loss: 0.00001427\n",
      "Epoch [40/60], Training Loss: 0.00001086, Test Loss: 0.00001573\n",
      "Epoch [50/60], Training Loss: 0.00001341, Test Loss: 0.00000860\n",
      "Epoch [60/60], Training Loss: 0.00001731, Test Loss: 0.00000999\n",
      "**********************************************\n",
      "The reinforce process [23], collecting data ...\n",
      "Episode [0/4], Reward: 28.77662874, Step: [260/20000]\n",
      "Episode [1/4], Reward: 23.28299641, Step: [219/20000]\n",
      "Episode [2/4], Reward: 26.67320812, Step: [241/20000]\n",
      "Episode [3/4], Reward: 29.73048145, Step: [268/20000]\n",
      "Totally collect 992 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5008 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1422.2836537361145 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001129, Test Loss: 0.00001896\n",
      "Epoch [20/60], Training Loss: 0.00001432, Test Loss: 0.00001422\n",
      "Epoch [30/60], Training Loss: 0.00000853, Test Loss: 0.00000778\n",
      "Epoch [40/60], Training Loss: 0.00001497, Test Loss: 0.00002256\n",
      "Epoch [50/60], Training Loss: 0.00001274, Test Loss: 0.00002464\n",
      "Epoch [60/60], Training Loss: 0.00001359, Test Loss: 0.00002487\n",
      "**********************************************\n",
      "The reinforce process [24], collecting data ...\n",
      "Episode [0/4], Reward: 30.37874278, Step: [275/20000]\n",
      "Episode [1/4], Reward: 23.84330708, Step: [222/20000]\n",
      "Episode [2/4], Reward: 20.26148964, Step: [193/20000]\n",
      "Episode [3/4], Reward: 57.01460320, Step: [488/20000]\n",
      "Totally collect 1182 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4818 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1503.2439365386963 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000930, Test Loss: 0.00000945\n",
      "Epoch [20/60], Training Loss: 0.00001383, Test Loss: 0.00002415\n",
      "Epoch [30/60], Training Loss: 0.00001989, Test Loss: 0.00001814\n",
      "Epoch [40/60], Training Loss: 0.00002316, Test Loss: 0.00001118\n",
      "Epoch [50/60], Training Loss: 0.00001967, Test Loss: 0.00001841\n",
      "Epoch [60/60], Training Loss: 0.00001715, Test Loss: 0.00002174\n",
      "**********************************************\n",
      "The reinforce process [25], collecting data ...\n",
      "Episode [0/4], Reward: 38.56131300, Step: [338/20000]\n",
      "Episode [1/4], Reward: 28.15881789, Step: [258/20000]\n",
      "Episode [2/4], Reward: 24.59620499, Step: [225/20000]\n",
      "Episode [3/4], Reward: 13.42139806, Step: [140/20000]\n",
      "Totally collect 965 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5035 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1272.0323872566223 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000863, Test Loss: 0.00000562\n",
      "Epoch [20/60], Training Loss: 0.00000582, Test Loss: 0.00000488\n",
      "Epoch [30/60], Training Loss: 0.00001017, Test Loss: 0.00000985\n",
      "Epoch [40/60], Training Loss: 0.00001552, Test Loss: 0.00001814\n",
      "Epoch [50/60], Training Loss: 0.00000856, Test Loss: 0.00001788\n",
      "Epoch [60/60], Training Loss: 0.00001920, Test Loss: 0.00001285\n",
      "**********************************************\n",
      "The reinforce process [26], collecting data ...\n",
      "Episode [0/4], Reward: 26.55903381, Step: [244/20000]\n",
      "Episode [1/4], Reward: 44.07082779, Step: [383/20000]\n",
      "Episode [2/4], Reward: 21.67727449, Step: [204/20000]\n",
      "Episode [3/4], Reward: 27.27252085, Step: [248/20000]\n",
      "Totally collect 1083 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4917 training data from all previous dataset, total training sample: 6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consume 1404.5267379283905 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000967, Test Loss: 0.00000861\n",
      "Epoch [20/60], Training Loss: 0.00001305, Test Loss: 0.00001138\n",
      "Epoch [30/60], Training Loss: 0.00001179, Test Loss: 0.00001083\n",
      "Epoch [40/60], Training Loss: 0.00001794, Test Loss: 0.00002187\n",
      "Epoch [50/60], Training Loss: 0.00002713, Test Loss: 0.00002961\n",
      "Epoch [60/60], Training Loss: 0.00000875, Test Loss: 0.00001259\n",
      "**********************************************\n",
      "The reinforce process [27], collecting data ...\n",
      "Episode [0/4], Reward: 25.11857823, Step: [229/20000]\n",
      "Episode [1/4], Reward: 17.44646216, Step: [170/20000]\n",
      "Episode [2/4], Reward: 16.74965102, Step: [164/20000]\n",
      "Episode [3/4], Reward: 24.54996976, Step: [227/20000]\n",
      "Totally collect 794 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5206 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1114.0295491218567 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001085, Test Loss: 0.00001144\n",
      "Epoch [20/60], Training Loss: 0.00001683, Test Loss: 0.00001225\n",
      "Epoch [30/60], Training Loss: 0.00002042, Test Loss: 0.00000842\n",
      "Epoch [40/60], Training Loss: 0.00001460, Test Loss: 0.00000809\n",
      "Epoch [50/60], Training Loss: 0.00001487, Test Loss: 0.00001480\n",
      "Epoch [60/60], Training Loss: 0.00000950, Test Loss: 0.00000861\n",
      "**********************************************\n",
      "The reinforce process [28], collecting data ...\n",
      "Episode [0/4], Reward: 22.53472826, Step: [213/20000]\n",
      "Episode [1/4], Reward: 36.64141322, Step: [322/20000]\n",
      "Episode [2/4], Reward: 16.56690499, Step: [165/20000]\n",
      "Episode [3/4], Reward: 27.70019869, Step: [252/20000]\n",
      "Totally collect 956 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5044 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1253.8923587799072 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000991, Test Loss: 0.00001387\n",
      "Epoch [20/60], Training Loss: 0.00000975, Test Loss: 0.00000703\n",
      "Epoch [30/60], Training Loss: 0.00003612, Test Loss: 0.00002902\n",
      "Epoch [40/60], Training Loss: 0.00000899, Test Loss: 0.00001141\n",
      "Epoch [50/60], Training Loss: 0.00000899, Test Loss: 0.00000907\n",
      "Epoch [60/60], Training Loss: 0.00001535, Test Loss: 0.00001320\n",
      "**********************************************\n",
      "The reinforce process [29], collecting data ...\n",
      "Episode [0/4], Reward: 17.65439465, Step: [176/20000]\n",
      "Episode [1/4], Reward: 23.91361958, Step: [222/20000]\n",
      "Episode [2/4], Reward: 48.20633148, Step: [418/20000]\n",
      "Episode [3/4], Reward: 22.23642513, Step: [209/20000]\n",
      "Totally collect 1029 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4971 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1293.2543783187866 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00001199, Test Loss: 0.00001075\n",
      "Epoch [20/60], Training Loss: 0.00003321, Test Loss: 0.00003781\n",
      "Epoch [30/60], Training Loss: 0.00002232, Test Loss: 0.00001953\n",
      "Epoch [40/60], Training Loss: 0.00001137, Test Loss: 0.00003788\n",
      "Epoch [50/60], Training Loss: 0.00002383, Test Loss: 0.00001765\n",
      "Epoch [60/60], Training Loss: 0.00000956, Test Loss: 0.00000605\n",
      "**********************************************\n",
      "The reinforce process [30], collecting data ...\n",
      "Episode [0/4], Reward: 24.26934618, Step: [223/20000]\n",
      "Episode [1/4], Reward: 26.54225697, Step: [244/20000]\n",
      "Episode [2/4], Reward: 25.44103073, Step: [234/20000]\n",
      "Episode [3/4], Reward: 27.62417540, Step: [252/20000]\n",
      "Totally collect 957 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5043 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1284.3271458148956 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000580, Test Loss: 0.00000892\n",
      "Epoch [20/60], Training Loss: 0.00000810, Test Loss: 0.00000775\n",
      "Epoch [30/60], Training Loss: 0.00001152, Test Loss: 0.00001171\n",
      "Epoch [40/60], Training Loss: 0.00001056, Test Loss: 0.00000871\n",
      "Epoch [50/60], Training Loss: 0.00000843, Test Loss: 0.00000813\n",
      "Epoch [60/60], Training Loss: 0.00001581, Test Loss: 0.00001611\n",
      "**********************************************\n",
      "The reinforce process [31], collecting data ...\n",
      "Episode [0/4], Reward: 22.73421898, Step: [214/20000]\n",
      "Episode [1/4], Reward: 17.45992167, Step: [170/20000]\n",
      "Episode [2/4], Reward: 20.94205632, Step: [197/20000]\n",
      "Episode [3/4], Reward: 24.62171517, Step: [228/20000]\n",
      "Totally collect 813 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5187 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1131.407683134079 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000537, Test Loss: 0.00000429\n",
      "Epoch [20/60], Training Loss: 0.00001016, Test Loss: 0.00001017\n",
      "Epoch [30/60], Training Loss: 0.00002736, Test Loss: 0.00001904\n",
      "Epoch [40/60], Training Loss: 0.00000888, Test Loss: 0.00001255\n",
      "Epoch [50/60], Training Loss: 0.00000619, Test Loss: 0.00000539\n",
      "Epoch [60/60], Training Loss: 0.00001926, Test Loss: 0.00002078\n",
      "**********************************************\n",
      "The reinforce process [32], collecting data ...\n",
      "Episode [0/4], Reward: 47.74940312, Step: [412/20000]\n",
      "Episode [1/4], Reward: 17.32954041, Step: [171/20000]\n",
      "Episode [2/4], Reward: 17.89592878, Step: [177/20000]\n",
      "Episode [3/4], Reward: 36.26986528, Step: [321/20000]\n",
      "Totally collect 1085 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 4915 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1698.2811131477356 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000417, Test Loss: 0.00000530\n",
      "Epoch [20/60], Training Loss: 0.00000499, Test Loss: 0.00000757\n",
      "Epoch [30/60], Training Loss: 0.00000495, Test Loss: 0.00000709\n",
      "Epoch [40/60], Training Loss: 0.00000806, Test Loss: 0.00000828\n",
      "Epoch [50/60], Training Loss: 0.00000893, Test Loss: 0.00001024\n",
      "Epoch [60/60], Training Loss: 0.00001731, Test Loss: 0.00002810\n",
      "**********************************************\n",
      "The reinforce process [33], collecting data ...\n",
      "Episode [0/4], Reward: 27.25038239, Step: [248/20000]\n",
      "Episode [1/4], Reward: 19.80591465, Step: [188/20000]\n",
      "Episode [2/4], Reward: 18.20176826, Step: [176/20000]\n",
      "Episode [3/4], Reward: 19.35478815, Step: [186/20000]\n",
      "Totally collect 802 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5198 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1129.44708943367 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000958, Test Loss: 0.00000795\n",
      "Epoch [20/60], Training Loss: 0.00001072, Test Loss: 0.00001189\n",
      "Epoch [30/60], Training Loss: 0.00000917, Test Loss: 0.00001069\n",
      "Epoch [40/60], Training Loss: 0.00000750, Test Loss: 0.00001831\n",
      "Epoch [50/60], Training Loss: 0.00000616, Test Loss: 0.00000907\n",
      "Epoch [60/60], Training Loss: 0.00001127, Test Loss: 0.00002592\n",
      "**********************************************\n",
      "The reinforce process [34], collecting data ...\n",
      "Episode [0/4], Reward: 25.06324965, Step: [230/20000]\n",
      "Episode [1/4], Reward: 39.54008760, Step: [345/20000]\n",
      "Episode [2/4], Reward: 25.81141897, Step: [237/20000]\n",
      "Episode [3/4], Reward: 17.33668072, Step: [172/20000]\n",
      "Totally collect 988 data based on MPC\n",
      "Saving all datas to storage/data_exp_1.pkl\n",
      "Sample 5012 training data from all previous dataset, total training sample: 6000\n",
      "Consume 1407.5302016735077 s in this iteration\n",
      "Total training step per epoch [24]\n",
      "Epoch [10/60], Training Loss: 0.00000919, Test Loss: 0.00000819\n",
      "Epoch [20/60], Training Loss: 0.00001501, Test Loss: 0.00001229\n",
      "Epoch [30/60], Training Loss: 0.00000970, Test Loss: 0.00001294\n",
      "Epoch [40/60], Training Loss: 0.00001565, Test Loss: 0.00001646\n",
      "Epoch [50/60], Training Loss: 0.00001046, Test Loss: 0.00001185\n",
      "Epoch [60/60], Training Loss: 0.00001002, Test Loss: 0.00001413\n",
      "**********************************************\n",
      "The reinforce process [35], collecting data ...\n",
      "Episode [0/4], Reward: 15.62845456, Step: [154/20000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2a71038a2175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**********************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The reinforce process [%s], collecting data ...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_mpc_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrewards_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/dynamics.py\u001b[0m in \u001b[0;36mcollect_mpc_dataset\u001b[0;34m(self, mpc, dynamic_model)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mstate_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_max_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mdata_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/controller.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, dynamic_model)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                   \u001b[0mmax_itrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_itrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                   verbose=False)\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(\"Solution: \",optimizer.solution[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(\"Fitness Value ABC: {0}\".format(optimizer.best))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/Hive/Hive.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# employees phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_employee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# onlookers phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/Hive/Hive.py\u001b[0m in \u001b[0;36msend_employee\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# computes fitness of mutant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mzombee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzombee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mzombee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/controller.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mstate_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mstate_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_tmp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstate_dt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/rl/RL-project/MPC/MPC-Double/dynamics.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mx_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not sure here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mout_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards_list = []\n",
    "for itr in range(config[\"dataset_config\"][\"n_mpc_itrs\"]):\n",
    "    t = time.time()\n",
    "    print(\"**********************************************\")\n",
    "    print(\"The reinforce process [%s], collecting data ...\" % itr)\n",
    "    rewards = data_fac.collect_mpc_dataset(mpc,model)\n",
    "    trainset, testset = data_fac.make_dataset()\n",
    "    rewards_list += rewards\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title('Reward Trend with %s iteration' % itr)\n",
    "    plt.plot(rewards_list)\n",
    "    plt.savefig(\"storage/reward-\" + str(model.exp_number) + \".png\")\n",
    "    print(\"Consume %s s in this iteration\" % (time.time()-t))\n",
    "    loss = model.train(trainset,testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
